{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iriyagupta/GENAI-BA-CPlus/blob/main/Basic_concepts_in_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNqAr_qJkJG0"
      },
      "source": [
        "**Neural Networks**\n",
        "* Rough idea: mimic the human brain (not that we know how that works!)\n",
        "* earn through examples with no procedural learning algorithm\n",
        "* As wikipedia says: <span style=\"color:blue\">vaguely</span> inspired by animal brains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UvdkeKpkJG2"
      },
      "source": [
        "**Structure of neural networks**\n",
        "* A neural network is a directed often acyclic graph\n",
        "* **Neurons**: nodes\n",
        "* **Synapses**: connections (edges) between nodes that contain weights\n",
        "* a neuron calculates a weighted sum of its input nodes and then decides whether to fire or not (should it react to the input or not)\n",
        "* **Activation functions**: the function that makes the activation decision\n",
        "* **Layers**: aggregations of neurons that use the same transformation function (different layers can use different functions)\n",
        "* **Input layer**: feature values from example cases enter the network here (think of it as the sensory organ of the network)\n",
        "* **Output layer**: the result (action) layer (classes, continuous values)\n",
        "* Hidden layers: all the layers between the input and output layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![neuron](neuron.png)"
      ],
      "metadata": {
        "id": "4pHhZ_RwCX2o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSQ2En9EkJG4"
      },
      "source": [
        "**Example of a network**\n",
        "from: https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![network](https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg)"
      ],
      "metadata": {
        "id": "pUFEL-E2Cgnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The idea in a neural network is that the weights represent knowledge\n",
        "* The network is trained with some input data using supervised learning\n",
        "* Most networks are complicated with many hidden layers and many (often millions) of synapses and weights\n",
        "* The weights in the trained network are the \"knowledge\" necessary for the network to give appropriate outputs\n",
        "* As more hidden layers are added, the network can learn more complex concepts"
      ],
      "metadata": {
        "id": "Vf1PFs5okhhA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia-0ECfKkJG5"
      },
      "source": [
        "**Rough procedure: \"for dummies\"!**\n",
        "* INITIALIZE: randomly assign weights to each connection\n",
        "* RUN:\n",
        "1. give an example to the network\n",
        "2. calculate the weighted sum of inputs at each neuron\n",
        "3. apply the activation function to that weighted sum\n",
        "4. do this layer by layer until you get the output layer values\n",
        "5. calculate the difference between calculated values and actual values\n",
        "6. tweak weights in the entire network so that the calculate output gets \"marginally\" closer to the actual value\n",
        "7. inse and repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amyl2Z53kJG5"
      },
      "source": [
        "**A super simple example**\n",
        "* Each input case has 3 features, each of which is either a 0 or a 1\n",
        "* We need to classify each input case into either a 0 or 1 (binary classification)\n",
        "* The actual \"real world\" rule is that <i>if feature 1 is 0, the case is classified as 0. If feature 1 is 1, the case is classified as 1</i></li>\n",
        "* (In other words, features 2 and 3 are noise and contain no information)</li>\n",
        "* We want the net to learn this"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![simple network](simple_network.png)"
      ],
      "metadata": {
        "id": "rxJ7pjFYCrpB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zd9zW12kJG6"
      },
      "source": [
        "**Define inputs and outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n17dSCSEkJG6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X = np.array([  [0,0,1], #Since the first value is 0, the output value is 0\n",
        "                [0,1,1], #Since the first value is 0, the output value is 0\n",
        "                [1,0,1], #Since the first value is 1, the output value is 1\n",
        "                [1,1,1]  #Since the first value is 1, the output value is 1\n",
        "                ])\n",
        "y = np.array([[0,0,1,1]]).T #Output array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKprPAQQkJG6"
      },
      "source": [
        "**Initialization**\n",
        "* generate random weights for every edge in the network\n",
        "* we'll use np.random.random (generates random numbers between 0 and 1)\n",
        "* and adjust the weights so that they are between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8M-RuKZkJG7",
        "outputId": "aaf7a59d-94d1-46e2-da56-127dbe04e9cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.25091976],\n",
              "       [ 0.90142861],\n",
              "       [ 0.46398788]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "np.random.seed(42) #Sets the seed for the random numbers\n",
        "\n",
        "#np.random.random((3,1)) returns a numpy array with 3 random numbers between 0 and 1\n",
        "#multiply each value by 2. This gives us values between 0 and 2\n",
        "#Subtract 1. This gives us values between -1 and 1\n",
        "syn0 = 2*np.random.random((3,1)) - 1\n",
        "syn0"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PZZbe2KvR7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnymZwXMkJG7"
      },
      "source": [
        "**Define the activation function**\n",
        "* Now we have input values (the X array) and weights (syn0)\n",
        "* We can use these values to calculate the output from the output node\n",
        "* The function that calculates the output of a node, given the inputs and the weights, is known as an **activation function**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbs0xNX6kJG7"
      },
      "source": [
        "**Let's see what our weighted sums look like**\n",
        "* for each input case we can calculat the weighted sum\n",
        "* $ \\sum_{i,j} syn0_{j}*X_{i,j} $ where i is the i-th input case and j is the each element of $X_{i}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4ynEd7AkJG7",
        "outputId": "050844d3-d6f0-4a0c-8968-e303bec19ed3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.46398788],\n",
              "       [1.3654165 ],\n",
              "       [0.21306812],\n",
              "       [1.11449673]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\n",
        "np.dot(X,syn0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1BrV2TykJG7"
      },
      "source": [
        "* Nice. We could say that anything less than 0 is a 0 and anything greater than 0 is a 1\n",
        "* And use these \"predicted\" 0s and 1s to compute the error\n",
        "* And use these errors to adjust weights\n",
        "* Not ideal, because:\n",
        "** learning would be binary and the model would keep switching from class 0 to class 1 as we give it more training samples\n",
        "** what we would like is for learning to be smooth\n",
        "** \"hmm, looks like a class 1 but i'll just tweak the probability that it is a class 1 rather than switch entirely to a class 1\"\n",
        "** \"that way, over time, I'll get more and more sure\"\n",
        "** Also, if we're  sure we've learned something, we want to change the weights by a lot less than if we're not very sure we've learned something\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8lBrunukJG7"
      },
      "source": [
        "<h2>Sigmoid function</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sigmoid function](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
      ],
      "metadata": {
        "id": "w5cP-QH-DEEs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf6bDyZJkJG7"
      },
      "source": [
        "The sigmoid function takes a number as its argument and returns a value between 0 and 1. It has the following properties:\n",
        "* $ sigmoid(x) = \\dfrac{1}{1+e^{-x}} $\n",
        "* sigmoid(0) returns 0.5\n",
        "* the derivative (slope) of the function is higher as values approach 0 and lower as values move away from 0\n",
        "* the derivative is easy to calculate because it is a function of the sigmoid value\n",
        "* $ \\dfrac{d}{dx}sigmoid(x) = sigmoid(x)*(1-sigmoid(x)) $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Complicated?**\n",
        "* Focus on:\n",
        "** Easy to calculate\n",
        "** calculated value is between 0 and 1\n",
        "** the derivative is easy to calculate\n",
        "** the derivative is used to tweak the weights\n",
        "** the derivative is lower the closer you are to 0 or 1 and the weights will change less in those cases (we are more sure!)"
      ],
      "metadata": {
        "id": "fzdfxzjnxXaw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbDFRcLTkJG7",
        "outputId": "ae13413d-3a64-4a30-8d85-3c4c90cfd2a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0024726231566347743 0.002466509291360048\n"
          ]
        }
      ],
      "source": [
        "#This function returns the sigmoid value (between 0 and 1)\n",
        "# and the derivative if the deriv = True\n",
        "def sigmoid(x,deriv=False):\n",
        "    if deriv:\n",
        "        return sigmoid(x)*(1-sigmoid(x))\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "print(sigmoid(-6),sigmoid(-6,True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anjXX-gYkJG8",
        "outputId": "62d72229-3ed7-4518-e8c3-87ca2ce278c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00020778770380880385\n",
            "0.009943400607141828\n",
            "0.011820097252632555\n",
            "0.012497396484210332\n",
            "0.00019773427522509594\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(sigmoid(5.5) - sigmoid(5.45))\n",
        "print(sigmoid(1.0) - sigmoid(0.95))\n",
        "print(sigmoid(.5) - sigmoid(.45))\n",
        "print(sigmoid(0.05) - sigmoid(0.0))\n",
        "print(sigmoid(-5.5) - sigmoid(-5.55))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv7Wqp2ekJG8"
      },
      "source": [
        "**Now let's train the network**\n",
        "* First we'll multiply X by the weight array to get the weighted sum of each input weight combination\n",
        "* Then apply the sigmoid function and get a value in the (0,1) range. This is the output value that we will use\n",
        "* level_0: First (input layer)\n",
        "* level_1: Second (hidden layer or the output layer in our case)\n",
        "* Then compute the error (y - level_1). Note that y is either 0 or 1 but the value of level_1 is between 0 and 1\n",
        "* Compute an adjustmant factor (delta). Multiply the error by the derivative of the sigmoid function\n",
        "* Use these deltas to adjust the weights\n",
        "* Repeat with the next set of training cases (or just give it the same set again)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The function *run_net* runs the network for us**\n",
        "* In each pass:\n",
        "** use the entire input to compute the error and adjust the weights\n",
        "** after n passes, the weights of the network will contain our rule"
      ],
      "metadata": {
        "id": "G_XribBj8EDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7NDFtbVxkJG8"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x,deriv=False):\n",
        "    if deriv:\n",
        "        return sigmoid(x)*(1-sigmoid(x))\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def run_net(X,y,activation_function=sigmoid,passes=10):\n",
        "    np.random.seed(1) #seed the random numbers\n",
        "    syn0 = 2*np.random.random((3,1)) - 1    #Calculate initial weights\n",
        "    for i in range(0,passes):\n",
        "        level_0 = X  #Input to the nn\n",
        "        level_1 = activation_function(np.dot(level_0,syn0)) #New weights\n",
        "        level_1_error = y - level_1 #error (note: y is 1/0; level_1 is (0,1))\n",
        "        #Get the derivative of the sigmoid (the change) and multiply by the error\n",
        "        level_1_delta = level_1_error * activation_function(level_1,True)\n",
        "        syn0 += np.dot(level_0.T,level_1_delta) #Update the weights (level_0 * deltas)\n",
        "    return syn0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEvwqig8kJG8",
        "outputId": "dcdd6fa6-0563-461e-a29d-9d0f2fc75907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.7600348 ],\n",
              "       [ 0.26494204],\n",
              "       [-0.86577132]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "final_weights = run_net(X,y,sigmoid,10)\n",
        "final_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2oqHrXwkJG8"
      },
      "source": [
        "**Generate predictions for the test sample**\n",
        "* Multiply the test input by the weights\n",
        "* Apply the sigmoid function\n",
        "* values greater than 0.5 implie 1; value less than 0.5 implie 0;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyVhtCqMkJG8",
        "outputId": "1189bc73-15ba-44f5-df04-52702c663fed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.76118833],\n",
              "       [0.35415399],\n",
              "       [0.85321402],\n",
              "       [0.29613496]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_X = np.array([[1,1,1],[0,1,1],[1,0,0],[0,0,1]])\n",
        "sigmoid(np.dot(test_X,final_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDQYNNVbkJG8"
      },
      "source": [
        "**100% accuracy!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbGxs338kJG8"
      },
      "source": [
        "**Walkthrough**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxL7g7PtkJG8",
        "outputId": "05a89f94-97fc-4395-d8ba-93ba0ff496bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.68801096]\n",
            " [-1.37597368]\n",
            " [-0.49069399]\n",
            " [-1.17865671]]\n",
            "level_0\n",
            "[[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [1 1 1]] \n",
            "\n",
            "syn0\n",
            "[[ 0.53548084]\n",
            " [-0.54931301]\n",
            " [-0.48107527]] \n",
            "\n",
            "level_1\n",
            "[[0.33447569]\n",
            " [0.20165642]\n",
            " [0.37973009]\n",
            " [0.23529381]] \n",
            "\n",
            "y\n",
            "[[0]\n",
            " [0]\n",
            " [1]\n",
            " [1]] \n",
            "\n",
            "level_1_error\n",
            "[[-0.33447569]\n",
            " [-0.20165642]\n",
            " [ 0.62026991]\n",
            " [ 0.76470619]] \n",
            "\n",
            "deriv\n",
            "[[0.24313621]\n",
            " [0.24747554]\n",
            " [0.24120006]\n",
            " [0.24657148]] \n",
            "\n",
            "level_1_delta\n",
            "[[-0.08132315]\n",
            " [-0.04990503]\n",
            " [ 0.14960914]\n",
            " [ 0.18855474]] \n",
            "\n",
            "new weights\n",
            "[[ 0.53548084]\n",
            " [-0.54931301]\n",
            " [-0.48107527]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "level_0 = X #Input layer\n",
        "syn0 = 2*np.random.random((3,1)) - 1 #initial weights\n",
        "print(np.dot(level_0,syn0))\n",
        "level_1 = sigmoid(np.dot(level_0,syn0)) #predicted y's\n",
        "level_1_error = y - level_1 #error\n",
        "level_1_delta = level_1_error * sigmoid(level_1,True) #change factor\n",
        "syn0 += np.dot(level_0.T,level_1_delta) #new weights\n",
        "print(\"level_0\")\n",
        "print(level_0,\"\\n\")\n",
        "print(\"syn0\")\n",
        "print(syn0,\"\\n\")\n",
        "print(\"level_1\")\n",
        "print(level_1,\"\\n\")\n",
        "print(\"y\")\n",
        "print(y,\"\\n\")\n",
        "print(\"level_1_error\")\n",
        "print(level_1_error,\"\\n\")\n",
        "print(\"deriv\")\n",
        "print(sigmoid(level_1,True),\"\\n\")\n",
        "print(\"level_1_delta\")\n",
        "print(level_1_delta,\"\\n\")\n",
        "print(\"new weights\")\n",
        "print(syn0,\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NsrZ22bkJG9"
      },
      "source": [
        "**Great! Let's try to find a different pattern**\n",
        "* If any two  or all three are 1, then the class is 1\n",
        "* Otherwise the class is zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Rcdgl1kJG9",
        "outputId": "4dd56733-cda0-4359-8974-f7f87eb08a89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.80577894],\n",
              "       [0.84660377],\n",
              "       [0.42913136],\n",
              "       [0.70142739]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import numpy as np\n",
        "X = np.array([[0,0,1],\n",
        "            [0,1,1],\n",
        "            [1,0,1],\n",
        "            [1,1,1],\n",
        "             [1,1,0],\n",
        "             [0,1,0],\n",
        "             [1,0,0],\n",
        "             [1,0,0]])\n",
        "\n",
        "y = np.array([[0],[1],[1],[1],[1],[0],[0],[0]])\n",
        "\n",
        "final_weights = run_net(X,y,sigmoid,10000)\n",
        "test_X = np.array([[1,1,1],[0,1,1],[1,0,0],[0,0,1]])\n",
        "sigmoid(np.dot(test_X,final_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egD1EcfCkJG9"
      },
      "source": [
        "**Not so good this time**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg9NqidDkJG9"
      },
      "source": [
        "* The pattern here is non-linear\n",
        "* Nonlinearities can be captured by adding layers to the network\n",
        "* We can try adding a hidden layer to our network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGvPdLy5kJG9"
      },
      "source": [
        "**Three layer network</h2>\n",
        "* Input layer: 3 nodes\n",
        "* Hidden layer: 4 nodes (the structure of the hidden layer is our choice)\n",
        "* Output: 1 node\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![network with hidden layer](multi layer network.png)"
      ],
      "metadata": {
        "id": "rLWdyimQEifd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwwJUwzNkJG9"
      },
      "source": [
        "**Initialize**\n",
        "* The network has two sets of weights\n",
        "* 1. set 1 between the input and the hidden layer\n",
        "* 2. set 2 between the hidden and the output layer\n",
        "*randomly assign weights at each level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bFZS4uLJkJHB"
      },
      "outputs": [],
      "source": [
        "syn0 = 2*np.random.random((3,4)) - 1\n",
        "syn1 = 2*np.random.random((4,1)) - 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93LwACcQkJHC"
      },
      "source": [
        "**feed forward network**\n",
        "* Calculate the node outputs at the hidden layer level\n",
        "* These become the inputs to the next layer (could be a hidden layer or, as in our case, the output layer)\n",
        "* In this manner, information moves from one layer to the next\n",
        "* This is known as a **feed forward network**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeQ-cMQpkJHC",
        "outputId": "370b62be-9a41-4413-bf95-c0d2f52f4ba5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5053376 ],\n",
              "       [0.50687089],\n",
              "       [0.51655106],\n",
              "       [0.51587768],\n",
              "       [0.46972561],\n",
              "       [0.45029194],\n",
              "       [0.46710261],\n",
              "       [0.46710261]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "level_0 = X\n",
        "level_1 = sigmoid(np.dot(level_0,syn0))\n",
        "level_2 = sigmoid(np.dot(level_1,syn1))\n",
        "level_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv6W4xRLkJHC"
      },
      "source": [
        "**Backpropagation**\n",
        "* Once information has moved all the way from the input layer, through the hidden layers, to the output layer, we have outputs from the network\n",
        "* These outputs can be compared with the actual outputs in the training data to get the error\n",
        "* This error needs to be propagated back through the hidden layers all the way to the input layer, adjusting weights between each set of layers\n",
        "* The process of propagating this error backward is known as **backpropagation**\n",
        "* The error is propagated back from the output layer to the input layer one layer at a time, adjusting weights along the way\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK8Y9rbJkJHC",
        "outputId": "bd0ba00f-ece2-4722-c694-2bd20a702370"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.5053376 ],\n",
              "       [ 0.49312911],\n",
              "       [ 0.48344894],\n",
              "       [ 0.48412232],\n",
              "       [ 0.53027439],\n",
              "       [-0.45029194],\n",
              "       [-0.46710261],\n",
              "       [-0.46710261]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "level_2_error = y - level_2\n",
        "level_2_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYJPDUjUkJHC",
        "outputId": "c978a7ac-655f-42d4-c0cf-c4fcccadaff9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.11860027],\n",
              "       [ 0.11569104],\n",
              "       [ 0.11314541],\n",
              "       [ 0.11332227],\n",
              "       [ 0.12551678],\n",
              "       [-0.10705403],\n",
              "       [-0.11063065],\n",
              "       [-0.11063065]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "level_2_delta = level_2_error*sigmoid(level_2,deriv=True)\n",
        "level_2_delta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTXypHq0kJHC"
      },
      "source": [
        "**Next, propagate the deltas back toward the input layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6-xGodlAkJHC"
      },
      "outputs": [],
      "source": [
        "level_1_error = level_2_delta.dot(syn1.T)\n",
        "level_1_delta = level_1_error * sigmoid(level_1,deriv=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQfpDZIukJHC"
      },
      "source": [
        "**Calculate the new weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcQn5HR-kJHC"
      },
      "outputs": [],
      "source": [
        "syn1 += level_1.T.dot(level_2_delta)\n",
        "syn0 += level_0.T.dot(level_1_delta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Ox__HPkJHC"
      },
      "source": [
        "**Putting it all together**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rQwMHePzkJHC"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x,deriv=False):\n",
        "    if deriv:\n",
        "        return x*(1-x)\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def run_net(X,y,activation_function=sigmoid,passes=10):\n",
        "    import time\n",
        "    np.random.seed(1)\n",
        "    syn0 = 2*np.random.random((3,4)) - 1\n",
        "    syn1 = 2*np.random.random((4,1)) - 1\n",
        "\n",
        "    for i in range(passes):\n",
        "        level_0 = X\n",
        "        level_1 = activation_function(np.dot(level_0,syn0))\n",
        "        level_2 = activation_function(np.dot(level_1,syn1))\n",
        "\n",
        "        level_2_error = y - level_2\n",
        "\n",
        "        level_2_delta = level_2_error*activation_function(level_2,deriv=True)\n",
        "\n",
        "        level_1_error = level_2_delta.dot(syn1.T)\n",
        "\n",
        "        level_1_delta = level_1_error * activation_function(level_1,deriv=True)\n",
        "\n",
        "        syn1 += level_1.T.dot(level_2_delta)\n",
        "        syn0 += level_0.T.dot(level_1_delta)\n",
        "    print(level_2)\n",
        "    return syn0,syn1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9yTso1mkJHC",
        "outputId": "45fe1a6e-91e3-4103-9ef3-29a0230f23e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29038182]\n",
            " [0.7597043 ]\n",
            " [0.72788203]\n",
            " [0.90378096]\n",
            " [0.73607507]\n",
            " [0.28925349]\n",
            " [0.19580023]\n",
            " [0.19580023]]\n"
          ]
        }
      ],
      "source": [
        "syn0,syn1 = run_net(X,y,activation_function=sigmoid,passes=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OE-cjtDkJHC"
      },
      "source": [
        "**Applying the net to test cases**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mimyjHRfkJHD",
        "outputId": "1d138689-6189-49e0-9acc-1f8c8765c1e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [0, 1, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "test_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3eZ1_DzkJHD",
        "outputId": "f8ca2409-f6b7-47da-e8e7-7bd1789de91e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.90480965],\n",
              "       [0.76030727],\n",
              "       [0.19489967],\n",
              "       [0.28910602]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "level_0 = test_X\n",
        "level_1 = sigmoid(np.dot(level_0,syn0))\n",
        "level_2 = sigmoid(np.dot(level_1,syn1))\n",
        "level_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szR-ZqIvkJHD"
      },
      "source": [
        "**In Summary**\n",
        "* By adding more hidden layers, the net can find patterns in higher dimensions\n",
        "* However, as we make the network more complex, the computational power required increases because both feed forward as well as back propagation will be multiplying increasingly larger matrices\n",
        "* But, because computing power has become cheap, and more accessible thanks to GPUs, neural networks are transforming AI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7iDaP6IkJHD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}